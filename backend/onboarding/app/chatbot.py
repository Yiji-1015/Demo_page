"""
RAG ì±—ë´‡ ë° ê²€ìƒ‰ ëª¨ë“ˆ
- Qdrant ë²¡í„° ê²€ìƒ‰
- LLM ê¸°ë°˜ ë‹µë³€ ìƒì„±
- ì¶œì²˜ ì¸ìš©
"""

from typing import List, Dict, Any
from openai import OpenAI
from qdrant_client import QdrantClient
from langchain_upstage import ChatUpstage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


class ConfluenceChatbot:
    """Confluence RAG ì±—ë´‡ í´ë˜ìŠ¤"""

    def __init__(
        self,
        upstage_api_key: str,
        qdrant_url: str,
        qdrant_api_key: str,
        collection_name: str = "confluence_docs",
        llm_model: str = "solar-pro"
    ):
        """
        Args:
            upstage_api_key: Upstage API í‚¤
            qdrant_url: Qdrant í´ë¼ìš°ë“œ URL
            qdrant_api_key: Qdrant API í‚¤
            collection_name: Qdrant ì»¬ë ‰ì…˜ ì´ë¦„
            llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸ (solar-pro, solar-mini ë“±)
        """
        self.collection_name = collection_name

        # Upstage ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸
        self.client_upstage = OpenAI(
            api_key=upstage_api_key,
            base_url="https://api.upstage.ai/v1"
        )

        # Qdrant í´ë¼ì´ì–¸íŠ¸
        self.client_qdrant = QdrantClient(
            url=qdrant_url,
            api_key=qdrant_api_key
        )

        # LLM ëª¨ë¸
        self.llm = ChatUpstage(
            model=llm_model,
            api_key=upstage_api_key
        )

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", """
            ë‹¹ì‹ ì€ ì‚¬ë‚´ ìœ„í‚¤(Confluence) ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ì›ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

            ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ [Context]ì— ìˆëŠ” ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
            ë§Œì•½ [Context]ì— ì •ë‹µì´ ì—†ë‹¤ë©´ ì†”ì§í•˜ê²Œ "ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë§í•˜ì„¸ìš”.
            ê±°ì§“ ì •ë³´ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

            ë‹µë³€ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë©°, í•„ìš”í•˜ë‹¤ë©´ ë²ˆí˜¸ë‚˜ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

            [Context]
            {context}
            """),
            ("human", "{question}"),
        ])

    def embedding(self, text: str) -> List[float]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸

        Returns:
            4096 ì°¨ì›ì˜ ì„ë² ë”© ë²¡í„°
        """
        response = self.client_upstage.embeddings.create(
            input=text,
            model="embedding-query"
        )
        return response.data[0].embedding

    def search_documents(
            self,
            query: str,
            top_k: int = 3,
            score_threshold: float = 0.0
        ) -> List[Dict[str, Any]]:
            """ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ Qdrantì—ì„œ ê²€ìƒ‰í•˜ê³  ë§í¬ë¥¼ ë³´ì •í•©ë‹ˆë‹¤."""
            print(f"ğŸ” ê²€ìƒ‰ì–´: '{query}'")

            query_vector = self.embedding(query)

            search_result = self.client_qdrant.query_points(
                collection_name=self.collection_name,
                query=query_vector,
                limit=top_k,
                with_payload=True,
                score_threshold=score_threshold
            )

            hits = search_result.points
            results = []
            
            for hit in hits:
                score = hit.score
                payload = hit.payload

                # --- ğŸ”— [ê¸´ê¸‰ ìˆ˜ì •] ë§í¬ ë³´ì • ë¡œì§ ì‹œì‘ ---
                raw_url = payload.get('source', '')
                page_id = payload.get('page_id', 'Unknown')
                space_key = payload.get('space_key', 'LLOYDK') # ê¸°ë³¸ê°’ ì„¤ì •

                # 1. ê³µë°± ì œê±° ë° ê¸°ë³¸ ë„ë©”ì¸ ì¶”ì¶œ (ì˜ˆ: lloydk.atlassian.net/wiki)
                if raw_url:
                    # ìŠ¬ë˜ì‹œê°€ ê²¹ì¹˜ê±°ë‚˜ í”„ë¡œí† ì½œì´ ë¹ ì§„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë„ë©”ì¸ ë¶€ë¶„ë§Œ ì •ì œ
                    base_domain = raw_url.split('/pages/')[0].rstrip('/')
                    if not base_domain.startswith('http'):
                        base_domain = f'https://{base_domain}'
                    
                    # 2. ìš”ì²­í•˜ì‹  í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì¬ì¡°í•©
                    # í˜•ì‹: https://ë„ë©”ì¸/spaces/ê³µê°„í‚¤/pages/í˜ì´ì§€ID
                    sanitized_url = f"{base_domain}/spaces/{space_key}/pages/{page_id}"
                else:
                    sanitized_url = "#" # ë§í¬ê°€ ì—†ì„ ê²½ìš°
                # --- ğŸ”— ë§í¬ ë³´ì • ë¡œì§ ë ---

                results.append({
                    "score": score,
                    "title": payload.get('title', 'ì œëª© ì—†ìŒ'),
                    "content": payload.get('page_content', ''),
                    "page_id": page_id,
                    "source": sanitized_url,  # ë³´ì •ëœ URLë¡œ êµì²´
                    "url": sanitized_url      # í”„ë¡ íŠ¸ì—”ë“œìš© í•„ë“œ
                })

            return results

    def format_documents(self, docs: List[Dict[str, Any]]) -> str:
        """
        ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ Context ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.

        Args:
            docs: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            Context ë¬¸ìì—´
        """
        context_text = ""
        for i, doc in enumerate(docs):
            context_text += f"[ë¬¸ì„œ {i+1}]: {doc['title']}\n"
            context_text += f"{doc['content']}\n"
            context_text += "-" * 20 + "\n"

        return context_text

    def ask(
        self,
        query: str,
        top_k: int = 3,
        score_threshold: float = 0.0,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """
        ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
            score_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜
            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€

        Returns:
            {
                "answer": "ë‹µë³€ í…ìŠ¤íŠ¸",
                "sources": [ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸]
            }
        """
        # 1. ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = self.search_documents(query, top_k, score_threshold)

        if not retrieved_docs:
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "sources": []
            }

        # 2. Context ìƒì„±
        context_str = self.format_documents(retrieved_docs)

        # 3. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
        chain = self.prompt_template | self.llm | StrOutputParser()

        answer = chain.invoke({
            "context": context_str,
            "question": query
        })

        # 4. ê²°ê³¼ ì¶œë ¥ (verbose)
        if verbose:
            print("\n" + "="*50)
            print("ğŸ¤– AI ë‹µë³€:")
            print(answer)
            print("="*50)

            print("\nğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ:")
            for doc in retrieved_docs:
                print(f"- {doc['title']} (ìœ ì‚¬ë„: {doc['score']:.2f})")
                print(f"  ë§í¬: {doc['source']}")

        return {
            "answer": answer,
            "sources": retrieved_docs
        }

    def ask_streaming(
        self,
        query: str,
        top_k: int = 3,
        score_threshold: float = 0.0
    ):
        """
        ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
            score_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜

        Yields:
            ë‹µë³€ ì²­í¬ ë° ì¶œì²˜ ì •ë³´
        """
        # 1. ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = self.search_documents(query, top_k, score_threshold)

        if not retrieved_docs:
            yield {
                "type": "answer",
                "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            }
            yield {
                "type": "sources",
                "content": []
            }
            return

        # 2. Context ìƒì„±
        context_str = self.format_documents(retrieved_docs)

        # 3. LLMìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„±
        chain = self.prompt_template | self.llm

        for chunk in chain.stream({
            "context": context_str,
            "question": query
        }):
            yield {
                "type": "answer",
                "content": chunk.content
            }

        # 4. ì¶œì²˜ ì •ë³´ ì „ì†¡
        yield {
            "type": "sources",
            "content": retrieved_docs
        }